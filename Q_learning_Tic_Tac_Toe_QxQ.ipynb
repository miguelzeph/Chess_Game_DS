{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T22:51:08.490850Z",
     "start_time": "2021-08-10T22:51:04.406944Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T22:51:08.534842Z",
     "start_time": "2021-08-10T22:51:08.494237Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Agent\n",
    "class Agent(object):\n",
    "\n",
    "    def __init__(self, lr, gamma, reward_player, ):\n",
    "        \n",
    "        # Rewards\n",
    "        self.reward_player = reward_player\n",
    "        # Learning Rate - 0 to 1\n",
    "        self.lr = lr\n",
    "        # Discount factor\n",
    "        self.gamma = gamma\n",
    "        # Players ( player_1 = 1 and player_2 = -1 )\n",
    "        self.player = 1 \n",
    "        \n",
    "        self.number_match = 0\n",
    "        \n",
    "        self.results ={\n",
    "            'win':0,\n",
    "            'draw':0,\n",
    "            'lost':0}\n",
    "        \n",
    "        self.Q_table = {\n",
    "            'states' : [],\n",
    "            'actions': ['(0, 0)','(0, 1)','(0, 2)','(1, 0)','(1, 1)','(1, 2)','(2, 0)','(2, 1)','(2, 2)'],\n",
    "            'Q': []\n",
    "        }\n",
    "        \n",
    "        self.path = {\n",
    "            'states':  [], # boards\n",
    "            'actions': [], # posição no tabuleiro\n",
    "        }\n",
    "        \n",
    "    def reset_game(self):\n",
    "        self.player = 1\n",
    "        self.path = {\n",
    "            'states': [],\n",
    "            'actions':[],\n",
    "        }\n",
    "    \n",
    "    def reset_historic_game(self):\n",
    "        self.results ={\n",
    "            'win':0,\n",
    "            'draw':0,\n",
    "            'lost':0}\n",
    "        \n",
    "    def save_result(self, resultado):\n",
    "        \n",
    "        if resultado == 1:\n",
    "            #print('won')\n",
    "            self.results['win'] += 1\n",
    "            \n",
    "        elif resultado == -1:\n",
    "            #print('lost')\n",
    "            self.results['lost'] += 1\n",
    "\n",
    "        else:\n",
    "            #print('draw')\n",
    "            self.results['draw'] += 1\n",
    "            \n",
    "    def Q_table_df(self):\n",
    "        \n",
    "        df = pd.DataFrame(\n",
    "            index= self.Q_table['states'],\n",
    "            columns= self.Q_table['actions'],\n",
    "            data = self.Q_table['Q']\n",
    "            )\n",
    "        return df\n",
    "    \n",
    "    def update_Q(self, reward):\n",
    "        \n",
    "        # Q(s,a) = Q(s,a) + alpha* ( R(s) + * Gamma * max_Q(s+1,:) - Q(s,a) ) )\n",
    "        # R(s) = Reward...\n",
    "        \n",
    "        \n",
    "        # Menor caminho para derrota, pontua mais. ( reward > 0 )\n",
    "        # Maior caminho para derrota, perde menos. ( reward < 0)\n",
    "        reward = reward / len(self.path['actions'])\n",
    "        \n",
    "        lr =    self.lr\n",
    "        gamma = self.gamma\n",
    "        \n",
    "        # Lista de Estados e Ações - Executados\n",
    "        states_actions = list( self.path.values() )\n",
    "\n",
    "        # Lista de Estados Reverso (pois iremos do FUTURO pro PASSADO)\n",
    "        states =  list( reversed( states_actions[0] ) )\n",
    "\n",
    "        # Lista de Ações Reverso   (pois iremos do FUTURO pro PASSADO)\n",
    "        actions = list( reversed( states_actions[1] ) )\n",
    "\n",
    "        # Marcador para eu saber onde estou\n",
    "        index = 0\n",
    "        for s2, a2 in zip( states, actions ):\n",
    "            \n",
    "            if reward >= 0: \n",
    "\n",
    "                try:\n",
    "                    # index  = 0 é a ultima ação que levou a vitória, derrota ou empate\n",
    "                    if index == 0:\n",
    "\n",
    "                        # Estado Atual\n",
    "                        s2 = self.Q_table['states'].index(str(s2))\n",
    "                        # Ação Atual\n",
    "                        a2 = self.Q_table['actions'].index(str(a2))\n",
    "\n",
    "                        self.Q_table['Q'][s2][a2] = lr * ( reward ) #self.Q_table['Q'][s2][a2] = reward \n",
    "\n",
    "\n",
    "                        # Fazer o mesmo, mas agora para o States adiantado\n",
    "                        ##### Next Value #####\n",
    "                        \n",
    "                        # ESTADO avançado\n",
    "                        index += 1\n",
    "\n",
    "                        s1 = states[index]\n",
    "                        s1 = self.Q_table['states'].index(str(s1))\n",
    "\n",
    "                        a1 = actions[index]\n",
    "                        a1 = self.Q_table['actions'].index(str(a1))\n",
    "\n",
    "                        # a2 -> Não precisamos, porque estamos interessado na ação com valor MÁXIMO\n",
    "                        # do respectivo ESTADO avançado Max_Q(s+1,: )... ou seja, deixa em aberto\n",
    "                        self.Q_table['Q'][s1][a1] += lr*( 0 + gamma*np.max( self.Q_table['Q'][s2] ) - self.Q_table['Q'][s1][a1] )\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        ##### pegar o index numérico dos States e Actions\n",
    "                        s2 = self.Q_table['states'].index(str(s2))\n",
    "                        a2 = self.Q_table['actions'].index(str(a2))\n",
    "\n",
    "                        # Fazer o mesmo, mas agora para o States adiantado\n",
    "                        ##### Next Value #####\n",
    "\n",
    "                        # ESTADO avançado\n",
    "                        index += 1\n",
    "\n",
    "                        s1 = states[index]\n",
    "                        s1 = self.Q_table['states'].index(str(s1))\n",
    "\n",
    "                        a1 = actions[index]\n",
    "                        a1 = self.Q_table['actions'].index(str(a1))\n",
    "\n",
    "                        # a2 -> Não precisamos, porque estamos interessado na ação com valor MÁXIMO\n",
    "                        # do respectivo ESTADO avançado Max_Q(s+1,: )... ou seja, deixa em aberto\n",
    "                        self.Q_table['Q'][s1][a1] += lr*( 0 + gamma*np.max( self.Q_table['Q'][s2] ) - self.Q_table['Q'][s1][a1] ) \n",
    "\n",
    "                # Não há mais Estados Adiantados para buscar.   \n",
    "                except IndexError:\n",
    "                    continue\n",
    "            \n",
    "            \n",
    "            if reward < 0:\n",
    "            # Se for negativo tem que pegar o MIN, pois foi uma jogada ruim\n",
    "                \n",
    "                try:\n",
    "                    # index  = 0 é a ultima ação que levou a vitóriam, ou derrota\n",
    "                    if index == 0:\n",
    "\n",
    "                        s2 = self.Q_table['states'].index(str(s2))\n",
    "                        a2 = self.Q_table['actions'].index(str(a2))\n",
    "\n",
    "                        self.Q_table['Q'][s2][a2] = lr* ( reward ) #self.Q_table['Q'][s2][a2] = reward \n",
    "\n",
    "\n",
    "                        # Fazer o mesmo, mas agora para o States adiantado\n",
    "                        ##### Next Value #####\n",
    "\n",
    "                        # ESTADO avançado\n",
    "                        index += 1\n",
    "\n",
    "                        s1 = states[index]\n",
    "                        s1 = self.Q_table['states'].index(str(s1))\n",
    "\n",
    "                        a1 = actions[index]\n",
    "                        a1 = self.Q_table['actions'].index(str(a1))\n",
    "\n",
    "                        # a2 -> Não precisamos, porque estamos interessado na ação com valor MÁXIMO\n",
    "                        # do respectivo ESTADO avançado Max_Q(s+1,: )... ou seja, deixa em aberto\n",
    "                        self.Q_table['Q'][s1][a1] += lr*( 0 + gamma*np.min( self.Q_table['Q'][s2] ) - self.Q_table['Q'][s1][a1] )\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        ##### pegar o index numérico dos States e Actions\n",
    "                        s2 = self.Q_table['states'].index(str(s2))\n",
    "                        a2 = self.Q_table['actions'].index(str(a2))\n",
    "\n",
    "                        # Fazer o mesmo, mas agora para o States adiantado\n",
    "                        ##### Next Value #####\n",
    "\n",
    "                        # ESTADO avançado\n",
    "                        index += 1\n",
    "\n",
    "                        s1 = states[index]\n",
    "                        s1 = self.Q_table['states'].index(str(s1))\n",
    "\n",
    "                        a1 = actions[index]\n",
    "                        a1 = self.Q_table['actions'].index(str(a1))\n",
    "\n",
    "                        # a2 -> Não precisamos, porque estamos interessado na ação com valor MÁXIMO\n",
    "                        # do respectivo ESTADO avançado Max_Q(s+1,: )... ou seja, deixa em aberto\n",
    "                        self.Q_table['Q'][s1][a1] += lr*( 0 + gamma*np.min( self.Q_table['Q'][s2] ) - self.Q_table['Q'][s1][a1] ) \n",
    "                        \n",
    "                # Não há mais Estados Adiantados para buscar.   \n",
    "                except IndexError:\n",
    "                    continue   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T22:51:08.733597Z",
     "start_time": "2021-08-10T22:51:08.537294Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Enviroment\n",
    "class Enviroment(object):\n",
    "\n",
    "    def __init__(self, epsilon):\n",
    "        \n",
    "        # randomness factor\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # Board (é nosso ESTADO ATUAL)\n",
    "        self.board = np.zeros((3,3))\n",
    "        \n",
    "        # posição jogada\n",
    "        self.pos = 0\n",
    "\n",
    "    def reset_game(self):\n",
    "        self.board = np.zeros((3,3))\n",
    "\n",
    "    # Plotar o Board\n",
    "    def draw_board(self):\n",
    "\n",
    "        draw = ''\n",
    "\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                simbolo = ''\n",
    "                # simbolo X (p1 = 1) ou O (p2 = -1)\n",
    "                if self.board[i][j] == 1:\n",
    "                    symbol = 'X'\n",
    "                elif self.board[i][j] == -1:\n",
    "                    symbol = 'O'\n",
    "                else:\n",
    "                    symbol = ' '\n",
    "\n",
    "                draw += '|'+symbol+''\n",
    "\n",
    "                if j == 2:\n",
    "\n",
    "                    draw +='|\\n-------\\n'\n",
    "        print(draw)\n",
    "\n",
    "    # Posições disponíveis\n",
    "    def available_moves(self):\n",
    "        return np.argwhere(self.board == 0)\n",
    "    # Jogar uma posição disponível\n",
    "    def available_move_choice(self):\n",
    "        return random.choice(self.available_moves())\n",
    "\n",
    "    # Checar Resultado    \n",
    "    def check_result(self):\n",
    "\n",
    "        # Row\n",
    "        if sum(self.board[0]) == 3 or sum(self.board[1]) == 3 or sum(self.board[2]) == 3:\n",
    "            #print('venceu')\n",
    "            return 1\n",
    "        if sum(self.board[0]) == -3 or sum(self.board[1]) == -3 or sum(self.board[2]) == -3:\n",
    "            #print('perdeu')\n",
    "            return -1\n",
    "        # Col\n",
    "        if sum(self.board[:,0]) == 3 or sum(self.board[:,1]) == 3 or sum(self.board[:,2]) == 3:\n",
    "            #print('venceu')\n",
    "            return 1\n",
    "        if sum(self.board[:,0]) == - 3 or sum(self.board[:,1]) == - 3 or sum(self.board[:,2]) == - 3:\n",
    "            #print('perdeu')\n",
    "            return -1\n",
    "        # Diagonal\n",
    "        if sum(self.board.diagonal()) == 3 or sum(np.fliplr(self.board).diagonal()) == 3:\n",
    "            #print('venceu')\n",
    "            return 1\n",
    "        if sum(self.board.diagonal()) == -3 or sum(np.fliplr(self.board).diagonal()) == -3:\n",
    "            #print('perdeu')\n",
    "            return -1\n",
    "        # Empate\n",
    "        if not 0 in self.board:\n",
    "            #print('empate')\n",
    "            return 0\n",
    "        \n",
    "        return 2\n",
    "\n",
    "        #########################################################\n",
    "        ## continua = 2, empate = 0, vitoria = 1, derrota = -1 ##\n",
    "        #########################################################\n",
    "\n",
    "    # Dar recompensa        \n",
    "    def reward(self, result, reward_player):\n",
    "\n",
    "        if result == 1:  # Vitória\n",
    "            return reward_player['win']\n",
    "\n",
    "        if result == -1: # Derrota\n",
    "            return reward_player['lost']\n",
    "        \n",
    "        if result == 0:  # Empate\n",
    "            return reward_player['draw']\n",
    "    \n",
    "    # jogada - Random \n",
    "    def select_pos_by_random(self, player, name):\n",
    "        \n",
    "        row_col = self.available_move_choice()\n",
    "        \n",
    "        row = row_col[0] # Linha\n",
    "        col = row_col[1] # Coluna\n",
    "\n",
    "        self.board[row][col] = player\n",
    "        \n",
    "        self.pos = row,col\n",
    "        \n",
    "        #print(name + f' jogou na posição { str(self.pos) }')\n",
    "           \n",
    "    # jogada - humano   \n",
    "    def select_pos_by_input(self, player, name):\n",
    "        \n",
    "        #os.system('clear')\n",
    "        # desenhar jogada do player \n",
    "        #self.draw_board()\n",
    "        while True:\n",
    "            row = int( input('Row: ') )\n",
    "            col = int( input('Col: ') )\n",
    "            \n",
    "            if [row,col] in self.available_moves().tolist(): # Refransforme Em lista... Array ele aceita \n",
    "                \n",
    "                self.board[row][col] = player\n",
    "                self.pos = row,col\n",
    "                break\n",
    "            else:\n",
    "                input('try other position...')\n",
    "    \n",
    "    # Através do estado atual (Seu board)... pegue a ação com maior Q\n",
    "    def select_pos_by_Q(self,player, name, Q_table):\n",
    "        \n",
    "        # jogada Aleatória ( Exploring )\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            \n",
    "            #print('********jogada aleatória - Caiu no EPSILON ***********')\n",
    "            \n",
    "            self.select_pos_by_random( player, name = 'player '+str( player ) )\n",
    "            \n",
    "        # Vai na tabela e joga ( Exploiting )\n",
    "        else:\n",
    "\n",
    "            # Se existir esse estado gravado...\n",
    "            if str(self.board) in Q_table['states']:\n",
    "                \n",
    "                index_state = Q_table['states'].index( str(self.board) )\n",
    "                #index_action= self.Q_table['Q'][index_state].index( str(np.max(self.Q_table['Q'][index_state])) )\n",
    "                #index_qmax = np.argmax(self.Q_table['Q'][index_state])\n",
    "\n",
    "\n",
    "                # pega todos valores de Q com respectivo index state na ordem DESCRESCENTE\n",
    "                # assim, se a posição máx já estiver ocupada, ele vai pro segundo maior e assim por diante.\n",
    "\n",
    "                #print(sorted( self.Q_table['Q'][index_state], reverse = True ) )\n",
    "                #input()\n",
    "                \n",
    "                valores_qmax = sorted( Q_table['Q'][index_state], reverse = True )\n",
    "                #print(valores_qmax)\n",
    "                \n",
    "                # pega o maior na ordem decrescente... \n",
    "                for qmax in valores_qmax:\n",
    "                    \n",
    "                    # logo se for Zero não temos estado treinado\n",
    "                    # ( Ou pode ser que todos são negativos e a posição zero é pq não pode ser jogada... complicou )\n",
    "                    #if all(valores_qmax) == qmax:  # qmax = 0\n",
    "                    #if qmax == 0:\n",
    "                        \n",
    "                        #print(f'********Jogada Aleatório - qmax = {qmax} ... não tem treino***********')\n",
    "                        \n",
    "                        #self.select_pos_by_random( player, name = 'player '+str( player ) )\n",
    "                        #break\n",
    "                    \n",
    "                    index_qmax = Q_table['Q'][index_state].index( qmax )\n",
    "\n",
    "                    action = Q_table['actions'][index_qmax]\n",
    "\n",
    "                    row = int(action[1:2])\n",
    "                    col = int(action[4:5])\n",
    "                    \n",
    "                    \n",
    "                    if [row,col] in self.available_moves().tolist(): # Refransforme Em lista... Array ele aceita  \n",
    "                        \n",
    "                        #print(f'******** Jogada Inteligente - melhor Q:{qmax}***********')\n",
    "                        \n",
    "                        self.board[row][col] = player\n",
    "                        self.pos = row,col # Atualiza pos atual\n",
    "                        \n",
    "                        break\n",
    "                        \n",
    "            # se não existir o ESTADO, joga aleatório mesmo\n",
    "            else:\n",
    "                \n",
    "                #print('********Jogada Aleatória - Não existe este Estado***********') \n",
    "                self.select_pos_by_random( player, name = 'player '+str(player) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T22:51:21.425114Z",
     "start_time": "2021-08-10T22:51:21.410493Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# funct to start the game\n",
    "def start():\n",
    "    while True:\n",
    "\n",
    "        ##################### Criação da Tabela Q (antes) - PLAYER 1 ###################\n",
    "        # Se não existe este Estado dentro da Tabela Q, adicione\n",
    "        if str(env.board) not in agent_1.Q_table['states']:\n",
    "\n",
    "            # 1-) Adicionar Estado Atual\n",
    "            agent_1.Q_table['states'].append( str(env.board ) )\n",
    "\n",
    "            # 2-) Add valor de Q\n",
    "            #agent_1.Q_table['Q'].append( [0,0,0,0,0,0,0,0,0] )\n",
    "            agent_1.Q_table['Q'].append( [99998,11111,99995,11112,99999,11113,99996,11114,99997] )\n",
    "        ###############################################################\n",
    "        \n",
    "        ##################### Criação da Tabela Q (antes) - PLAYER 2 ###################\n",
    "        # Se não existe este Estado dentro da Tabela Q, adicione\n",
    "        if str(env.board) not in agent_2.Q_table['states']:\n",
    "\n",
    "            # 1-) Adicionar Estado Atual\n",
    "            agent_2.Q_table['states'].append( str(env.board ) )\n",
    "\n",
    "            # 2-) Add valor de Q\n",
    "            agent_2.Q_table['Q'].append( [99998,11111,99995,11112,99999,11113,99996,11114,99997] )\n",
    "        ###############################################################\n",
    "\n",
    "        # Registrar o State Inicial no PATH - Player 1\n",
    "        agent_1.path['states'].append( str(env.board) )\n",
    "        \n",
    "        # Registrar o State Inicial no PATH - Player 2\n",
    "        agent_2.path['states'].append( str(env.board) )\n",
    "\n",
    "        ############################ Agente Executa Ação no Ambiente #################### \n",
    "        if agent_1.player == 1: # PLAYER 1\n",
    "            env.select_pos_by_Q( agent_1.player,name = 'player '+str(agent_1.player),Q_table = agent_1.Q_table)\n",
    "            #env.select_pos_by_random( agent_1.player, name = 'player '+str(agent_1.player) )  \n",
    "            #env.select_pos_by_input( agent_1.player, name = 'player '+str(agent_1.player) )\n",
    "\n",
    "            # ( Desenha  Board )\n",
    "            #env.draw_board()\n",
    "            \n",
    "        else:               # PLAYER 2 \n",
    "            env.select_pos_by_Q( agent_2.player,name = 'player '+str(agent_2.player),Q_table = agent_2.Q_table)\n",
    "            #env.select_pos_by_random( agent_2.player, name = 'player '+str(agent_2.player) )\n",
    "            #env.select_pos_by_input( agent_2.player, name = 'player '+str(agent_2.player) )\n",
    "            \n",
    "            # ( Desenha  Board )\n",
    "            #env.draw_board()\n",
    "        #################################################################################\n",
    "\n",
    "        # Registrar o Action realizada no PATH\n",
    "        agent_1.path['actions'].append( str(env.pos) )\n",
    "        \n",
    "        # Registrar o Action realizada no PATH\n",
    "        agent_2.path['actions'].append( str(env.pos) )\n",
    "\n",
    "        ########################## Ambiente Responde ######################################\n",
    "        # checa resultado\n",
    "        if env.check_result() != 2: # continua = 2, empate = 0, vitoria = 1, derrota = -1\n",
    "\n",
    "            # resultado do jogo\n",
    "            agent_1.save_result( env.check_result() )\n",
    "            agent_2.save_result( -1 * env.check_result() )\n",
    "\n",
    "            # Valor da Recompensa\n",
    "            reward_1 = env.reward( result = env.check_result(), reward_player = agent_1.reward_player  )\n",
    "            reward_2 = env.reward( result = -1 * env.check_result(), reward_player = agent_2.reward_player  )\n",
    "            \n",
    "            \n",
    "            # Update Q Table\n",
    "            agent_1.update_Q( reward_1 )\n",
    "            agent_2.update_Q( reward_2 )\n",
    "\n",
    "            # Reset Game\n",
    "            env.reset_game()\n",
    "            agent_1.reset_game()\n",
    "            agent_2.reset_game()\n",
    "\n",
    "            \n",
    "            # add partida jogada\n",
    "            agent_1.number_match += 1\n",
    "            agent_2.number_match += 1\n",
    "\n",
    "            break\n",
    "\n",
    "        # Mudar jogador    \n",
    "        agent_1.player *= -1 # switch players\n",
    "        agent_2.player *= -1 # switch players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T22:51:38.441555Z",
     "start_time": "2021-08-10T22:51:38.425977Z"
    },
    "code_folding": [
     1,
     18
    ]
   },
   "outputs": [],
   "source": [
    "# SAVE\n",
    "def save_Q_table():\n",
    "    \n",
    "    # Player 1\n",
    "    with open(\"./trained_QxQ/Q_table_1.pkl\", \"wb\") as tf:\n",
    "        pickle.dump(agent_1.Q_table,tf)\n",
    "\n",
    "    with open(\"./trained_QxQ/partidas_1.pkl\", \"wb\") as tf:\n",
    "        pickle.dump(agent_1.number_match,tf)\n",
    "    \n",
    "    # Player 2\n",
    "    with open(\"./trained_QxQ/Q_table_2.pkl\", \"wb\") as tf:\n",
    "        pickle.dump(agent_2.Q_table,tf)\n",
    "\n",
    "    with open(\"./trained_QxQ/partidas_2.pkl\", \"wb\") as tf:\n",
    "        pickle.dump(agent_2.number_match,tf)\n",
    "\n",
    "# LOAD\n",
    "def load_Q_table():\n",
    "    # Player 2\n",
    "    with open('./trained_QxQ/Q_table_1.pkl', 'rb') as handle:\n",
    "        Q_table_1 = pickle.load(handle)\n",
    "    with open('./trained_QxQ/partidas_1.pkl', 'rb') as handle:\n",
    "        number_match_1 = pickle.load(handle)\n",
    "        \n",
    "    # Player 2\n",
    "    with open('./trained_QxQ/Q_table_2.pkl', 'rb') as handle:\n",
    "        Q_table_2 = pickle.load(handle)\n",
    "    with open('./trained_QxQ/partidas_2.pkl', 'rb') as handle:\n",
    "        number_match_2 = pickle.load(handle)\n",
    "\n",
    "    agent_1.number_match = number_match_1\n",
    "    agent_1.Q_table = Q_table_1\n",
    "    \n",
    "    agent_2.number_match = number_match_1\n",
    "    agent_2.Q_table = Q_table_2\n",
    "\n",
    "    print(f\"número de partidas {agent_1.number_match}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T22:58:19.965970Z",
     "start_time": "2021-08-10T22:58:19.958162Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Player 1\n",
    "agent_1 = Agent( \n",
    "    lr = 0.7, # Learning Rate\n",
    "    gamma = 0.7, # Discount Factor\n",
    "    reward_player = {\n",
    "        'win': 1,\n",
    "        'lost': -1,\n",
    "        'draw': 0.0,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Player 2\n",
    "agent_2 = Agent( \n",
    "    lr = 0.7, # Learning Rate\n",
    "    gamma = 0.7, # Discount Factor\n",
    "    reward_player = {\n",
    "        'win': 1,\n",
    "        'lost': -1,\n",
    "        'draw': 0.0, \n",
    "    }\n",
    ")\n",
    "\n",
    "# Load Q Table\n",
    "#load_Q_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T22:58:23.849928Z",
     "start_time": "2021-08-10T22:58:23.845509Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Object Enviroment\n",
    "env = Enviroment(\n",
    "    epsilon =  0.00, # Randomness Factor to execute one diferente moviment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T23:07:59.051860Z",
     "start_time": "2021-08-10T23:07:57.694457Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epsilon = 1.0 -----------------------------\n",
      "Player 1 - Win: 4595  Draw: 4628  Loss: 2007  -> epoch : 16088\n",
      "Player 2 - Win: 2007  Draw: 4628  Loss: 4595  -> epoch : 16088\n",
      "------------------------------------------------------------\n",
      "---------------- Epsilon = 0.9 -----------------------------\n",
      "Player 1 - Win:   7  Draw:   1  Loss:   2  -> epoch : 16098\n",
      "Player 2 - Win:   2  Draw:   1  Loss:   7  -> epoch : 16098\n",
      "------------------------------------------------------------\n",
      "---------------- Epsilon = 0.8 -----------------------------\n",
      "Player 1 - Win:   4  Draw:   2  Loss:   4  -> epoch : 16108\n",
      "Player 2 - Win:   4  Draw:   2  Loss:   4  -> epoch : 16108\n",
      "------------------------------------------------------------\n",
      "---------------- Epsilon = 0.7000000000000001 -----------------------------\n",
      "Player 1 - Win:   6  Draw:   1  Loss:   3  -> epoch : 16118\n",
      "Player 2 - Win:   3  Draw:   1  Loss:   6  -> epoch : 16118\n",
      "------------------------------------------------------------\n",
      "---------------- Epsilon = 0.6000000000000001 -----------------------------\n",
      "Player 1 - Win:   6  Draw:   3  Loss:   1  -> epoch : 16128\n",
      "Player 2 - Win:   1  Draw:   3  Loss:   6  -> epoch : 16128\n",
      "------------------------------------------------------------\n",
      "---------------- Epsilon = 0.5 -----------------------------\n",
      "Player 1 - Win:   4  Draw:   6  Loss:   0  -> epoch : 16138\n",
      "Player 2 - Win:   0  Draw:   6  Loss:   4  -> epoch : 16138\n",
      "------------------------------------------------------------\n",
      "---------------- Epsilon = 0.4 -----------------------------\n",
      "Player 1 - Win:   4  Draw:   4  Loss:   2  -> epoch : 16148\n",
      "Player 2 - Win:   2  Draw:   4  Loss:   4  -> epoch : 16148\n",
      "------------------------------------------------------------\n",
      "---------------- Epsilon = 0.30000000000000004 -----------------------------\n",
      "Player 1 - Win:   3  Draw:   6  Loss:   1  -> epoch : 16158\n",
      "Player 2 - Win:   1  Draw:   6  Loss:   3  -> epoch : 16158\n",
      "------------------------------------------------------------\n",
      "---------------- Epsilon = 0.2 -----------------------------\n",
      "Player 1 - Win:   2  Draw:   6  Loss:   2  -> epoch : 16168\n",
      "Player 2 - Win:   2  Draw:   6  Loss:   2  -> epoch : 16168\n",
      "------------------------------------------------------------\n",
      "---------------- Epsilon = 0.1 -----------------------------\n",
      "Player 1 - Win:   2  Draw:   8  Loss:   0  -> epoch : 16178\n",
      "Player 2 - Win:   0  Draw:   8  Loss:   2  -> epoch : 16178\n",
      "------------------------------------------------------------\n",
      "---------------- Epsilon = 0.0 -----------------------------\n",
      "Player 1 - Win:   0  Draw:  10  Loss:   0  -> epoch : 16188\n",
      "Player 2 - Win:   0  Draw:  10  Loss:   0  -> epoch : 16188\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Execution Random Env epsilon\n",
    "\n",
    "def exec_random():\n",
    "    # Random Variando\n",
    "    inter = 0.1\n",
    "     \n",
    "    for e in reversed( np.arange(0.0, 1.0 + inter, inter ) ):\n",
    "        env.epsilon = e\n",
    "        print(f'---------------- Epsilon = {e} -----------------------------')\n",
    "        \n",
    "        for epoch in range(1):\n",
    "            matches = 10\n",
    "            for i in range(matches):\n",
    "                start()\n",
    "            \n",
    "            escrever = \"Player 1 - Win: %3i  Draw: %3i  Loss: %3i \"%(agent_1.results['win'],agent_1.results['draw'],agent_1.results['lost'])\n",
    "            print( escrever + \" -> epoch : \" + str(agent_1.number_match) )\n",
    "            agent_1.reset_historic_game()\n",
    "\n",
    "            escrever = \"Player 2 - Win: %3i  Draw: %3i  Loss: %3i \"%(agent_2.results['win'],agent_2.results['draw'],agent_2.results['lost'])\n",
    "            print( escrever + \" -> epoch : \" + str(agent_2.number_match) )\n",
    "            agent_2.reset_historic_game()\n",
    "\n",
    "            print('------------------------------------------------------------')\n",
    "            #print(agent_1.Q_table_df().shape)\n",
    "            \n",
    "            \n",
    "    \n",
    "exec_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T23:03:55.864902Z",
     "start_time": "2021-08-10T23:03:55.857024Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# teste plotar\n",
    "\"\"\"# Execution Random Env epsilon\n",
    "\n",
    "graf_1 = {\n",
    "    'epsilon':[],\n",
    "    'win':[],\n",
    "    'draw':[],\n",
    "    'lost':[],\n",
    "}\n",
    "\n",
    "\n",
    "def exec_random():\n",
    "    # Random Variando\n",
    "    inter = 0.1\n",
    "     \n",
    "    for e in reversed( np.arange(0.0, 1.0 + inter, inter ) ):\n",
    "        env.epsilon = e\n",
    "        print(f'---------------- Epsilon = {e} -----------------------------')\n",
    "        \n",
    "        for epoch in range(1):\n",
    "            matches = 10\n",
    "            for i in range(matches):\n",
    "                start()\n",
    "                \n",
    "\n",
    "            graf_1['win'].append(agent_1.results['win'])\n",
    "            graf_1['draw'].append(agent_1.results['draw'])\n",
    "            graf_1['lost'].append(agent_1.results['lost'])\n",
    "\n",
    "            escrever = \"Player 1 - Win: %3i  Draw: %3i  Loss: %3i \"%(agent_1.results['win'],agent_1.results['draw'],agent_1.results['lost'])\n",
    "            print( escrever + \" -> epoch : \" + str(agent_1.number_match) )\n",
    "            agent_1.reset_historic_game()\n",
    "\n",
    "            escrever = \"Player 2 - Win: %3i  Draw: %3i  Loss: %3i \"%(agent_2.results['win'],agent_2.results['draw'],agent_2.results['lost'])\n",
    "            print( escrever + \" -> epoch : \" + str(agent_2.number_match) )\n",
    "            agent_2.reset_historic_game()\n",
    "\n",
    "            print('------------------------------------------------------------')\n",
    "            #print(agent_1.Q_table_df().shape)\n",
    "            \n",
    "        \n",
    "        graf_1['epsilon'].append(e)\n",
    "\n",
    "    \n",
    "exec_random()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(graf_1['epsilon'],graf_1['win'],'.-',label = 'win')\n",
    "plt.plot(graf_1['epsilon'],graf_1['draw'],'.-',label='draw')\n",
    "plt.plot(graf_1['epsilon'],graf_1['lost'],'.-',label='lost')\n",
    "plt.title(\" 100 matches played by epsilon\")\n",
    "plt.xlim( graf_1['epsilon'][0], graf_1['epsilon'][len(graf_1['epsilon']) -1] )\n",
    "plt.xlabel('Epsilon (random factor)')\n",
    "plt.ylabel('count of win,lost,draw')\n",
    "plt.grid(ls = 'dashdot')\n",
    "plt.legend()\n",
    "plt.plot()\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T23:00:11.076938Z",
     "start_time": "2021-08-10T22:59:58.645627Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Win:   0  Draw: 526  Lost:   0  -> epoch : 2636\n",
      " Win:   0  Draw: 526  Lost:   0  -> epoch : 2636\n",
      "\n",
      "\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 2736\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 2736\n",
      "\n",
      "\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 2836\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 2836\n",
      "\n",
      "\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 2936\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 2936\n",
      "\n",
      "\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 3036\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 3036\n",
      "\n",
      "\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 3136\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 3136\n",
      "\n",
      "\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 3236\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 3236\n",
      "\n",
      "\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 3336\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 3336\n",
      "\n",
      "\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 3436\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 3436\n",
      "\n",
      "\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 3536\n",
      " Win:   0  Draw: 100  Lost:   0  -> epoch : 3536\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normal Execution\n",
    "\n",
    "def exec_normal():\n",
    "    # K = epoch\n",
    "    for k in range(10):\n",
    "\n",
    "        #  Train 100 x por época\n",
    "        partidas = 100\n",
    "        for i in range(partidas):\n",
    "            start()\n",
    "        escrever = \" Win: %3i  Draw: %3i  Lost: %3i \"%(agent_1.results['win'],agent_1.results['draw'],agent_1.results['lost'])\n",
    "        print( escrever + \" -> epoch : \" + str(agent_1.number_match) )\n",
    "        agent_1.reset_historic_game()\n",
    "\n",
    "        escrever = \" Win: %3i  Draw: %3i  Lost: %3i \"%(agent_2.results['win'],agent_2.results['draw'],agent_2.results['lost'])\n",
    "        print( escrever + \" -> epoch : \" + str(agent_2.number_match) )\n",
    "        agent_2.reset_historic_game()\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "exec_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T23:08:11.692482Z",
     "start_time": "2021-08-10T23:08:11.649890Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | |X|\n",
      "-------\n",
      "| | | |\n",
      "-------\n",
      "| | | |\n",
      "-------\n",
      "\n",
      "| | |X|\n",
      "-------\n",
      "|O| | |\n",
      "-------\n",
      "| | | |\n",
      "-------\n",
      "\n",
      "| | |X|\n",
      "-------\n",
      "|O|X| |\n",
      "-------\n",
      "| | | |\n",
      "-------\n",
      "\n",
      "| | |X|\n",
      "-------\n",
      "|O|X| |\n",
      "-------\n",
      "|O| | |\n",
      "-------\n",
      "\n",
      "|X| |X|\n",
      "-------\n",
      "|O|X| |\n",
      "-------\n",
      "|O| | |\n",
      "-------\n",
      "\n",
      "|X| |X|\n",
      "-------\n",
      "|O|X| |\n",
      "-------\n",
      "|O| |O|\n",
      "-------\n",
      "\n",
      "|X| |X|\n",
      "-------\n",
      "|O|X| |\n",
      "-------\n",
      "|O|X|O|\n",
      "-------\n",
      "\n",
      "|X|O|X|\n",
      "-------\n",
      "|O|X| |\n",
      "-------\n",
      "|O|X|O|\n",
      "-------\n",
      "\n",
      "|X|O|X|\n",
      "-------\n",
      "|O|X|X|\n",
      "-------\n",
      "|O|X|O|\n",
      "-------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Area of Test\n",
    "\n",
    "def start_test():\n",
    "    while True:\n",
    "\n",
    "        ##################### Criação da Tabela Q (antes) - PLAYER 1 ###################\n",
    "        # Se não existe este Estado dentro da Tabela Q, adicione\n",
    "        if str(env.board) not in agent_1.Q_table['states']:\n",
    "\n",
    "            # 1-) Adicionar Estado Atual\n",
    "            agent_1.Q_table['states'].append( str(env.board ) )\n",
    "\n",
    "            # 2-) Add valor de Q\n",
    "            agent_1.Q_table['Q'].append( [99998,11111,99995,11112,99999,11113,99996,11114,99997] )\n",
    "            ###############################################################\n",
    "        \n",
    "        ##################### Criação da Tabela Q (antes) - PLAYER 2 ###################\n",
    "        # Se não existe este Estado dentro da Tabela Q, adicione\n",
    "        if str(env.board) not in agent_2.Q_table['states']:\n",
    "\n",
    "            # 1-) Adicionar Estado Atual\n",
    "            agent_2.Q_table['states'].append( str(env.board ) )\n",
    "\n",
    "            # 2-) Add valor de Q\n",
    "            agent_2.Q_table['Q'].append( [99998,11111,99995,11112,99999,11113,99996,11114,99997] )\n",
    "        ###############################################################\n",
    "\n",
    "\n",
    "        # Registrar o State Inicial no PATH - Player 1\n",
    "        agent_1.path['states'].append( str(env.board) )\n",
    "        \n",
    "        # Registrar o State Inicial no PATH - Player 2\n",
    "        agent_2.path['states'].append( str(env.board) )\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        ############################ Agente Executa Ação no Ambiente #################### \n",
    "        if agent_1.player == 1: # PLAYER 1\n",
    "            env.select_pos_by_Q( agent_1.player,name = 'player '+str(agent_1.player),Q_table = agent_1.Q_table)\n",
    "            #env.select_pos_by_random( agent_1.player, name = 'player '+str(agent_1.player) )  \n",
    "            #env.select_pos_by_input( agent_1.player, name = 'player '+str(agent_1.player) )\n",
    "\n",
    "            # ( Desenha  Board )\n",
    "            env.draw_board()\n",
    "            \n",
    "        else:               # PLAYER 2 \n",
    "            env.select_pos_by_Q( agent_2.player,name = 'player '+str(agent_2.player),Q_table = agent_2.Q_table)\n",
    "            #env.select_pos_by_random( agent_2.player, name = 'player '+str(agent_2.player) )\n",
    "            #env.select_pos_by_input( agent_2.player, name = 'player '+str(agent_2.player) )\n",
    "            \n",
    "            # ( Desenha  Board )\n",
    "            env.draw_board()\n",
    "        #################################################################################\n",
    "\n",
    "\n",
    "        # Registrar o Action realizada no PATH\n",
    "        agent_1.path['actions'].append( str(env.pos) )\n",
    "        \n",
    "        # Registrar o Action realizada no PATH\n",
    "        agent_2.path['actions'].append( str(env.pos) )\n",
    "\n",
    "\n",
    "        ########################## Ambiente Responde ######################################\n",
    "        # checa resultado\n",
    "        if env.check_result() != 2: # continua = 2, empate = 0, vitoria = 1, derrota = -1\n",
    "\n",
    "            # resultado do jogo\n",
    "            agent_1.save_result( env.check_result() )\n",
    "            agent_2.save_result( -1 * env.check_result() )\n",
    "\n",
    "            # Valor da Recompensa\n",
    "            reward_1 = env.reward( result = env.check_result(), reward_player = agent_1.reward_player  )\n",
    "            reward_2 = env.reward( result = -1 * env.check_result(), reward_player = agent_2.reward_player  )\n",
    "            \n",
    "            \n",
    "            # Update Q Table\n",
    "            agent_1.update_Q( reward_1 )\n",
    "            agent_2.update_Q( reward_2 )\n",
    "\n",
    "            # Reset Game\n",
    "            env.reset_game()\n",
    "            agent_1.reset_game()\n",
    "            agent_2.reset_game()\n",
    "\n",
    "            \n",
    "            # add partida jogada\n",
    "            agent_1.number_match += 1\n",
    "            agent_2.number_match += 1\n",
    "\n",
    "            break\n",
    "            \n",
    "\n",
    "\n",
    "        # Mudar jogador    \n",
    "        agent_1.player *= -1 # switch players\n",
    "        agent_2.player *= -1 # switch players\n",
    "        \n",
    "#agent_1.reward_player['draw'] = -0.1\n",
    "        \n",
    "start_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T23:01:06.726317Z",
     "start_time": "2021-08-10T23:01:06.700145Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0, 0)</th>\n",
       "      <th>(0, 1)</th>\n",
       "      <th>(0, 2)</th>\n",
       "      <th>(1, 0)</th>\n",
       "      <th>(1, 1)</th>\n",
       "      <th>(1, 2)</th>\n",
       "      <th>(2, 0)</th>\n",
       "      <th>(2, 1)</th>\n",
       "      <th>(2, 2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]</th>\n",
       "      <td>22521.248836</td>\n",
       "      <td>20933.9411</td>\n",
       "      <td>26443.339996</td>\n",
       "      <td>22003.114047</td>\n",
       "      <td>22524.809684</td>\n",
       "      <td>23580.907973</td>\n",
       "      <td>69997.2</td>\n",
       "      <td>19066.264736</td>\n",
       "      <td>23334.0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 1.]]</th>\n",
       "      <td>35443.790000</td>\n",
       "      <td>11111.0000</td>\n",
       "      <td>99995.000000</td>\n",
       "      <td>52333.110000</td>\n",
       "      <td>33741.050459</td>\n",
       "      <td>11113.000000</td>\n",
       "      <td>99996.0</td>\n",
       "      <td>11114.000000</td>\n",
       "      <td>99997.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[[ 0.  0.  0.]\\n [ 0. -1.  0.]\\n [ 0.  0.  1.]]</th>\n",
       "      <td>99998.000000</td>\n",
       "      <td>11111.0000</td>\n",
       "      <td>99995.000000</td>\n",
       "      <td>11112.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>7635.409100</td>\n",
       "      <td>99996.0</td>\n",
       "      <td>11114.000000</td>\n",
       "      <td>99997.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[[ 0.  0.  0.]\\n [ 0. -1.  1.]\\n [ 0.  0.  1.]]</th>\n",
       "      <td>99998.000000</td>\n",
       "      <td>11111.0000</td>\n",
       "      <td>99995.000000</td>\n",
       "      <td>11112.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>11113.000000</td>\n",
       "      <td>99996.0</td>\n",
       "      <td>8778.590000</td>\n",
       "      <td>99997.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[[ 0.  0.  0.]\\n [ 0. -1.  1.]\\n [ 0. -1.  1.]]</th>\n",
       "      <td>35443.790000</td>\n",
       "      <td>11111.0000</td>\n",
       "      <td>99995.000000</td>\n",
       "      <td>11112.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>11113.000000</td>\n",
       "      <td>99996.0</td>\n",
       "      <td>11114.000000</td>\n",
       "      <td>99997.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       (0, 0)      (0, 1)  \\\n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           22521.248836  20933.9411   \n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 1.]]           35443.790000  11111.0000   \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  0.]\\n [ 0.  0.  1.]]  99998.000000  11111.0000   \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  1.]\\n [ 0.  0.  1.]]  99998.000000  11111.0000   \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  1.]\\n [ 0. -1.  1.]]  35443.790000  11111.0000   \n",
       "\n",
       "                                                       (0, 2)        (1, 0)  \\\n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           26443.339996  22003.114047   \n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 1.]]           99995.000000  52333.110000   \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  0.]\\n [ 0.  0.  1.]]  99995.000000  11112.000000   \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  1.]\\n [ 0.  0.  1.]]  99995.000000  11112.000000   \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  1.]\\n [ 0. -1.  1.]]  99995.000000  11112.000000   \n",
       "\n",
       "                                                       (1, 1)        (1, 2)  \\\n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           22524.809684  23580.907973   \n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 1.]]           33741.050459  11113.000000   \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  0.]\\n [ 0.  0.  1.]]  99999.000000   7635.409100   \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  1.]\\n [ 0.  0.  1.]]  99999.000000  11113.000000   \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  1.]\\n [ 0. -1.  1.]]  99999.000000  11113.000000   \n",
       "\n",
       "                                                  (2, 0)        (2, 1)  \\\n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           69997.2  19066.264736   \n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 1.]]           99996.0  11114.000000   \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  0.]\\n [ 0.  0.  1.]]  99996.0  11114.000000   \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  1.]\\n [ 0.  0.  1.]]  99996.0   8778.590000   \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  1.]\\n [ 0. -1.  1.]]  99996.0  11114.000000   \n",
       "\n",
       "                                                     (2, 2)  \n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           23334.0101  \n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 1.]]           99997.0000  \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  0.]\\n [ 0.  0.  1.]]  99997.0000  \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  1.]\\n [ 0.  0.  1.]]  99997.0000  \n",
       "[[ 0.  0.  0.]\\n [ 0. -1.  1.]\\n [ 0. -1.  1.]]  99997.0000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q_TABLE ---> States X Actions\n",
    "agent_1.Q_table_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:36:07.648915Z",
     "start_time": "2021-05-04T12:36:07.545044Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0, 0)</th>\n",
       "      <th>(0, 1)</th>\n",
       "      <th>(0, 2)</th>\n",
       "      <th>(1, 0)</th>\n",
       "      <th>(1, 1)</th>\n",
       "      <th>(1, 2)</th>\n",
       "      <th>(2, 0)</th>\n",
       "      <th>(2, 1)</th>\n",
       "      <th>(2, 2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]</th>\n",
       "      <td>69995.610921</td>\n",
       "      <td>34284.258007</td>\n",
       "      <td>69996.500000</td>\n",
       "      <td>47323.279462</td>\n",
       "      <td>69999.300000</td>\n",
       "      <td>48997.549986</td>\n",
       "      <td>68687.596413</td>\n",
       "      <td>34299.313929</td>\n",
       "      <td>69994.582312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[[1. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]</th>\n",
       "      <td>99998.000000</td>\n",
       "      <td>7021.938539</td>\n",
       "      <td>24728.924976</td>\n",
       "      <td>54789.667010</td>\n",
       "      <td>19466.182523</td>\n",
       "      <td>49938.557776</td>\n",
       "      <td>11202.740473</td>\n",
       "      <td>21124.642444</td>\n",
       "      <td>69998.599950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[[ 1.  0.  0.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]</th>\n",
       "      <td>99998.000000</td>\n",
       "      <td>4676.824097</td>\n",
       "      <td>69449.936919</td>\n",
       "      <td>49470.498505</td>\n",
       "      <td>49552.914126</td>\n",
       "      <td>11113.000000</td>\n",
       "      <td>17789.136701</td>\n",
       "      <td>8314.605304</td>\n",
       "      <td>50332.891034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[[ 1.  1.  0.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]</th>\n",
       "      <td>99998.000000</td>\n",
       "      <td>11111.000000</td>\n",
       "      <td>35442.890000</td>\n",
       "      <td>4964.090751</td>\n",
       "      <td>49809.473294</td>\n",
       "      <td>11113.000000</td>\n",
       "      <td>4652.810492</td>\n",
       "      <td>8778.590000</td>\n",
       "      <td>51180.930656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[[ 1.  1. -1.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]</th>\n",
       "      <td>99998.000000</td>\n",
       "      <td>11111.000000</td>\n",
       "      <td>99995.000000</td>\n",
       "      <td>11112.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>11113.000000</td>\n",
       "      <td>34300.309100</td>\n",
       "      <td>11114.000000</td>\n",
       "      <td>31632.539990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       (0, 0)        (0, 1)  \\\n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           69995.610921  34284.258007   \n",
       "[[1. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           99998.000000   7021.938539   \n",
       "[[ 1.  0.  0.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  99998.000000   4676.824097   \n",
       "[[ 1.  1.  0.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  99998.000000  11111.000000   \n",
       "[[ 1.  1. -1.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  99998.000000  11111.000000   \n",
       "\n",
       "                                                       (0, 2)        (1, 0)  \\\n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           69996.500000  47323.279462   \n",
       "[[1. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           24728.924976  54789.667010   \n",
       "[[ 1.  0.  0.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  69449.936919  49470.498505   \n",
       "[[ 1.  1.  0.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  35442.890000   4964.090751   \n",
       "[[ 1.  1. -1.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  99995.000000  11112.000000   \n",
       "\n",
       "                                                       (1, 1)        (1, 2)  \\\n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           69999.300000  48997.549986   \n",
       "[[1. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           19466.182523  49938.557776   \n",
       "[[ 1.  0.  0.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  49552.914126  11113.000000   \n",
       "[[ 1.  1.  0.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  49809.473294  11113.000000   \n",
       "[[ 1.  1. -1.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  99999.000000  11113.000000   \n",
       "\n",
       "                                                       (2, 0)        (2, 1)  \\\n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           68687.596413  34299.313929   \n",
       "[[1. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           11202.740473  21124.642444   \n",
       "[[ 1.  0.  0.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  17789.136701   8314.605304   \n",
       "[[ 1.  1.  0.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]   4652.810492   8778.590000   \n",
       "[[ 1.  1. -1.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  34300.309100  11114.000000   \n",
       "\n",
       "                                                       (2, 2)  \n",
       "[[0. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           69994.582312  \n",
       "[[1. 0. 0.]\\n [0. 0. 0.]\\n [0. 0. 0.]]           69998.599950  \n",
       "[[ 1.  0.  0.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  50332.891034  \n",
       "[[ 1.  1.  0.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  51180.930656  \n",
       "[[ 1.  1. -1.]\\n [ 0.  0. -1.]\\n [ 0.  0.  0.]]  31632.539990  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q_TABLE ---> States X Actions\n",
    "agent_2.Q_table_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:36:07.716364Z",
     "start_time": "2021-05-04T12:36:07.652346Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE Q Table\n",
    "#save_Q_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T23:02:16.473634Z",
     "start_time": "2021-08-10T23:02:16.467409Z"
    }
   },
   "outputs": [],
   "source": [
    "#agent_1.number_match"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
